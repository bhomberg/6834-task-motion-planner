\documentclass[12pt]{article}

\usepackage{fancyhdr} % Required for custom headers
\usepackage{float}
\usepackage{lastpage} % Required to determine the last page for the footer
\usepackage{extramarks} % Required for headers and footers
\usepackage{graphicx} % Required to insert images
\usepackage{amssymb}
\usepackage{enumerate}
\usepackage{svg}
\usepackage{caption}
\usepackage{subfig}


% Margins
\topmargin=-.5in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9in
\headsep=0.25in
\graphicspath{{./figures/}}
\DeclareGraphicsExtensions{.jpg,.png,.svg}

\newcommand{\tab}{\hspace*{2em}}

\title{Combined Task and Motion Planner through an Interface Layer}
\author{Alex Gutierrez (ragtz@mit.edu), Bianca Homberg (bhomberg@mit.edu), \\and Veronica Lane (vmlane@mit.edu)}


%% ONE SENTENCE PER LINE TO MAKE THIS WORK NICELY IN GIT

\begin{document}

\maketitle 


\section{Testing}

\subsection{Baxter Robot}

We ran our test scenarios on the Baxter robot [Fig. \ref{fig:baxter}], designed by Rethink Robotics. 
Baxter is a humanoid robot with two 7 degree of freedom arms. 
Our tests used only the right arm with two finger gripper.

\begin{figure}[h]
\centering
\includegraphics[width=.2\textwidth]{baxter}
\caption{The Baxter Robot \label{fig:baxter}}
\end{figure}

\subsection{Test Scenarios}

We present an interface between a task planner and motion planner [1]. 
Baxter executes a variety of tests to measure the performance of the interface layer. 
The tests demonstrate that the interface layer respects all of the geometric constraints. 
Baxter picks up objects in a reasonable order to avoid collisions.

The goal of the first test is to move the object at the center of a 3x3 square grid of objects to a goal surface. 
The goal of the second test is to sort red, green, and blue blocks into separate bins.
Figure \ref{fig:scenarios} shows the setup of the different test scenarios. 

\begin{figure}[h]
\centering
\def\svgwidth{.4\textwidth}
\input{figures/scenarios.pdf_tex}
\caption{Set up of test scenarios.\label{fig:scenarios}}
\end{figure}

\section{Technical Approach}
The three components of our combined task and motion planner system are:  \(1\) the task planner, \(2\) the motion planner, and \(3\) the interface layer. 
The interface layer is composed of the state update and pose generator modules [Fig. \ref{fig:blockDiagram}].

\begin{figure}[h]
\centering
\def\svgwidth{0.5\textwidth}
\input{figures/blockDiagram.pdf_tex}
\caption{System Block Diagram\label{fig:blockDiagram}}
\end{figure}

\subsection{Task Planner}
We used the FF task planner. 
Our software for the task planner is the same as the previous problem set. 
The task planner is instantiated with a given PDDL domain file.  
As a ROS service, it takes in a PDDL problem specification of current state and goal from the interface layer. 
It returns a set of actions leading to the desired goal state. 

\subsection{Motion Planner}
We used the MoveIt! motion planner. 
[TODO: Alex will write this]

\subsection{Interface}

\begin{figure}[t]
\centering
\includegraphics[width=\textwidth]{figures/figure4.png}
\caption{Illustration of the interface layerâ€™s refinement process. 
Action arguments have been abbreviated. 
Taken from [1]
\label{fig:figure4}}
\end{figure}

\subsubsection{Algorithm 1}

\begin{figure}[t]
	\centering
	\subfloat{\includegraphics[width=.45\linewidth]{figures/algorithm1}}
	\qquad
	\subfloat{\includegraphics[width=.45\linewidth]{figures/algorithm2}}
	\caption{Taken from[1]\label{fig:algorithms}}
\end{figure}

We start with an initial state where no objects obstruct any motions.  
From there, we look for a high level plan.  
If we do succeed at finding a high level task plan, we begin the process of attempting to find a motion corresponding to each action.

First, we start by attempting to find a full refinement of the whole plan, calling the TryRefine subroutine in error-free mode.  
If that succeeds, then we return the plan.  

If that does not succeed, we find a partial trajectory that goes as far as it can by calling the TryRefine subroutine in partial trajectory mode.  
This function returns a partial trajectory along with the step where it failed and the determined cause for failure.  
Then, we update the state based on the actions up until that point and add in the obstructing obstacles corresponding to the failure.  
Now, we attempt to find a new high level plan, and iterate.  

If we fail to find a new high level plan at any point, we re-run the TryRefine subroutine on the original high level plan from the previous step.  
Since the TryRefine subroutine has randomization from pose generators, re-running it may yield a better solution. 

We have several checks where, if we fail to find a solution, we clear all of our information and start over.  
Due to the randomization of the pose generators, we may make better choices during subsequent iterations.  

The original version of the algorithm, as shown in \ref{fig:algorithms}, only attempts to find partial trajectories when it replans partway through the procedure.  
For our version of the algorithm, every time a new partial plan is generated, we first try to fill it completely using backtracking search (calling TryRefine in error-free mode) before giving up and resorting to the partial trajectory finding.  

\subsubsection{Algorithm 2}


In the TryRefine subroutine, the interface layer attempts to find motion plans corresponding to the various actions.  
It has two modes: error free and partial trajectory.  
In error free mode, it performs backtracking search to try to find a full plan from start to finish.  

In partial trajectory mode, TryRefine goes as far as it can, but when it finds an infeasible motion plan for some action, it returns the step at which it failed.  
In addition to returning the failed step, it returns the cause of the errors.  
The function MPErrs removes various objects from the environment until it find a plan which succeeds.  
It then marks all of those objects which were removed as blocking objects.

As described above in Algorithm 1, once the list of blocking objects is returned, the interface layer updates the state and attempts to replan from there.

\subsubsection{State Update}


When an action is infeasible because an object is blocking another object, the interface layer updates the state and calls the task planner. 
The interface layer, as described above, determines a list of obstructing objects.
The state update function goes through a section of a high level plan, performing all of the actions and updating the current state of the world.
Once the state update function reaches the step where the tryRefine function failed, the state update function adds predicates to the state describing which blocks obstruct other blocks.
The state function updates each action based on the preconditions and postconditions of each action: it confirms that all of the preconditions are satisfied and then adds true postconditions and removes falsified postconditions.  

For instance, for the PICKUP action, the state update functions confirms that the gripper is empty, adds the postcondition that the gripper is full and that the object is in the gripper and removes the postcondition that the object is on whichever surface it started on.
%If the object is movable, the task planner will generate a plan to move the object out of the way before moving the target object. 
%If the object is not movable, such as the table, the interface will perform backtracking search to try to find a full plan from start to finish.
%The backtracking search is over possible pose instantiations: since some poses may be infeasible and since previous choices may affect future choices, the backtracking search iterates over all possible poses in order to find a full solution if a full solution exists. 

%Every time a new partial plan is generated, we first try to fill it completely using backtracking search before giving up and resorting to the partial trajectory finding.  
%In our manipulation example, the interface tries to pick up blocks from all angles before giving up and assuming they must be blocked by something.  

\subsubsection{Pose Generator}

When the pose generator is called by the interface layer, it generates a set of random poses for each action. 
Each pose is made up of a set of waypoints. 

For the PICKUP action, it generates the following waypoints: near the object and pointing towards it, touching the object, lifting the object, and a standard home position. 
The first waypoint is randomly generated and places the gripper about 15 centimeters away from the object.
We divided the set of possible random yaw angles around the object into several distinct ranges, called \textit{slices}. 
Each call to the pose generator generates a random angle in one of the ranges.
The second waypoint moves the arm so that the gripper can object. 
The third waypoint is in the exact same position with the gripper closed. 
The next waypoint is directly above the previous waypoint, high enough so that the object is above all of the other objects on the table. 
Finally, the last waypoint goes to the standard home position for the square grid task and moves  above the correct bin for the sorting task.

For the PUTDOWN action, the pose generator generates the following waypoints: above the target location, at the target location with the gripper closed, at the target location with the gripper open, 15 cm backed away from the target location, and the standard home position. 
The target location is randomly generated, but the pose generator checks to make sure that no objects are at or near the target location.

To reiterate, a pose is a set of waypoints. 
The pose generator keeps track of the number of poses it has generated, at least one for each slice. 
Once the pose generator has generated the maximum number of poses, it returns None, to indicate that no poses are feasible. 
The interface layer then backtracks and resets the pose generator. 
The TryRefine method of the interface layer attempts to generate a feasible motion plan between each pose.  
The motion planner is called to create this motion plan, including motion plans between waypoints.

\section{Improvements}

We implemented a number of improvements in order to increase the efficiency of the algorithm.

\subsection{Error-free mode}

\subsection{Motion Planner Heuristic}

\subsection{O(n) Identification of Obstructions}

To find the blocking objects, we start by iterating through a randomized list of the objects.  
We continue removing objects until we find a successful motion plan.  
We will eventually find a successful motion plan since if there are no other objects in the world, the motion should succeed.  
After we find this possible list of removed objects, we iterate through all of the objects we removed.  
We attempt to add these objects in one by one, leaving added in all of those which do not obstruct our found motion plan.  
This leaves us with a local minimum of removed objects: it may be possible to find another smaller set of objects that, if removed, allow a valid motion plan.  
However, for this set of this set of objects, no object can be added back in without obstructing the motion plan.
This algorithm for determining obstructing objects is $O(n)$.

The paper originally describes an $O(n^2)$ algorithm for determining obstructing objects, starting by removing each individual object, then pairs of objects, etc.  
This ensures a minimum removal set but requires significantly more motion planner calls.


\section{Results}
\subsection{Metrics}
We measured the performance of each test by the runtime and the number of calls to both the task planner and motion planner [Fig. \ref{benchmark}]. 
The interface layer is designed to be independent of any specific task and motion planner libraries, therefore the number of calls to the motion and task planner measures the performance of the interface layer better than the total runtime. 
The actual runtime depends on the motion planner and task planner chosen.

\subsection{Square Grid}
We ran the square grid scenario on a simulated Baxter robot.
The planner took approximately an hour to find a feasible plan. 
In simulation, Baxter successfully moves blocks to reach the target center block and places the center block on the target surface.
A video of the successful test trial in simulation can be found at [TODO: link here].

\subsection{Sorting}
We ran the sorting task in simulation and on the physical Baxter robot.
The planner took approximately an hour to find a feasible plan. 
We ran many test trials to achieve a successful run because the system was open-loop with respect to the environment.
It had feedback on the world position of the arms, but not on the position of the arms relative to the objects. This mean that drift accumulated over time.
Baxter successfully sorts green, red, and blue blocks into different bins. 
A video of the successful test trial can be found at http://youtu.be/445_t_lUBdU.
\begin{figure}
\begin{tabular}[t]{|l|l|l|l|l|l|l|}
\hline

Shape & Blocks & \shortstack{Goal Number of\\Blocks to Move} & Obstructions & \shortstack{Motion Planner\\Calls} & \shortstack{Task Planner\\Calls} & Runtime \\ \hline
Square & 9 & 56 & ? & ? & ?& ? \\
\hline
Sorting & 9 & 56 & ? & ? & ?& ?\\
\hline

\end {tabular}
\caption{Test Scenarios Performance}
\label{benchmark}
\end{figure}

\section{Limitations}

\section{Optimizations}

\section{References}

[1] S. Srivastava, E. Fang, L. Riano, R. Chitnis, S. Russell, P. Abbeel. \"Combined Task and Motion Planning Through an Extensible Planner-Independent Interface Layer\". IEEE International Conference on Robotics and Automation (ICRA), 2014.

\end{document}

